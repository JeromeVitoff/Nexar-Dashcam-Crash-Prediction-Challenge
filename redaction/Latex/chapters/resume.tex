\section*{Résumé}

La prédiction précoce de collisions routières représente un enjeu majeur pour la sécurité routière, avec plus de 1,3 million de décès annuels dans le monde. Ce mémoire présente une analyse comparative systématique de six architectures de deep learning pour la prédiction de collisions à partir de vidéos dashcam, dans le cadre du Challenge Kaggle Nexar.

Notre méthodologie repose sur l'évaluation expérimentale de trois familles d'architectures : les modèles hybrides CNN-RNN (ResNet-LSTM, EfficientNet-GRU), les CNN 3D natifs (I3D, R(2+1)D), et les Vision Transformers (TimeSformer, VideoMAE). L'ensemble des modèles a été entraîné sur un dataset de 1,500 vidéos annotées et évalué selon la métrique Mean Average Precision (mAP).

Les résultats expérimentaux révèlent plusieurs enseignements clés. Les modèles 3D CNN pré-entraînés sur Kinetics-400 obtiennent les meilleures performances, avec I3D atteignant 77,53\% d'Average Precision en validation et 71,2\% sur le test set Kaggle. Les architectures hybrides offrent un excellent compromis vitesse-performance, EfficientNet-GRU atteignant 71\% d'accuracy et 74,95\% d'AP. En revanche, les Vision Transformers sans pré-entraînement vidéo échouent complètement (TimeSformer : 50,67\%), démontrant l'importance critique du pre-training sur données vidéo pour ces architectures.

Cette recherche établit des recommandations pratiques pour le développement de systèmes ADAS : privilégier les CNN 3D pour maximiser la performance de prédiction, opter pour des architectures hybrides pour les contraintes temps réel, et systématiquement utiliser du pré-entraînement sur datasets vidéo massifs pour les architectures transformer. Les perspectives incluent l'optimisation des modèles via techniques d'interprétabilité et le déploiement en conditions réelles.

\vspace{0.5cm}

\textbf{Mots-clés :} Deep Learning, Vision par Ordinateur, Prédiction de Collisions, CNN 3D, Vision Transformers, ADAS, Sécurité Routière, Kaggle

\section*{Abstract}

Early collision prediction represents a major challenge for road safety, with over 1.3 million annual deaths worldwide. This thesis presents a systematic comparative analysis of six deep learning architectures for collision prediction from dashcam videos, as part of the Kaggle Nexar Challenge.

Our methodology is based on experimental evaluation of three architecture families: hybrid CNN-RNN models (ResNet-LSTM, EfficientNet-GRU), native 3D CNNs (I3D, R(2+1)D), and Vision Transformers (TimeSformer, VideoMAE). All models were trained on a dataset of 1,500 annotated videos and evaluated using the Mean Average Precision (mAP) metric.

Experimental results reveal several key insights. 3D CNN models pre-trained on Kinetics-400 achieve the best performance, with I3D reaching 77.53\% Average Precision on validation and 71.2\% on the Kaggle test set. Hybrid architectures offer an excellent speed-performance trade-off, with EfficientNet-GRU achieving 71\% accuracy and 74.95\% AP. However, Vision Transformers without video pre-training fail completely (TimeSformer: 50.67\%), demonstrating the critical importance of pre-training on video data for these architectures.

This research establishes practical recommendations for ADAS system development: favor 3D CNNs to maximize prediction performance, opt for hybrid architectures for real-time constraints, and systematically use pre-training on massive video datasets for transformer architectures. Future work includes model optimization through interpretability techniques and deployment in real-world conditions.

\vspace{0.5cm}

\textbf{Keywords:} Deep Learning, Computer Vision, Collision Prediction, 3D CNN, Vision Transformers, ADAS, Road Safety, Kaggle
